# MNIST_Simple_NN
### Creating a simple neural network, with two linear function and one RELU as activation function
### Using Cross entropy loss as the loss function(softmax used internally)
